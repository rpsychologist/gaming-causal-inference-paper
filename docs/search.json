[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Harmful Compared to What? The Problem of Gaming and Ill-defined Causal Effects - Online Supplement",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(broom)\nextrafont::loadfonts(quiet = TRUE)\nlibrary(see)\nknitr::opts_chunk$set(\n    message = FALSE,\n    warning = FALSE,\n    cache = TRUE\n)\nlibrary(knitr)\ncol1 &lt;- \"#2980b9\"\ncol2 &lt;- \"#be4048\""
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Harmful Compared to What? The Problem of Gaming and Ill-defined Causal Effects - Online Supplement",
    "section": "Introduction",
    "text": "Introduction\nThis is the online supplement for Harmful Compared to What? The Problem of Gaming and Ill-defined Causal Effects (Magnusson, Johansson, & Przybylski, 2023, preprint), containing the code for all calculations and figures presented in the article.\n\nPreprint\nGitHub respository\nOSF repository\nOnline version of the supplement"
  },
  {
    "objectID": "index.html#exchangeability-example",
    "href": "index.html#exchangeability-example",
    "title": "Harmful Compared to What? The Problem of Gaming and Ill-defined Causal Effects - Online Supplement",
    "section": "Exchangeability example",
    "text": "Exchangeability example\nThis function was created to simulate a binary confounder.\n\n#' Simulate binary confounder\n#'\n#' Will generate a dataset with a binary exposure and confounder with an\n#' observed difference of a specific magnitude, while the true average\n#' causal effect is zero.\n#'\n#' @param n number of participants per group\n#' @param m_young Mean outcome among the young people\n#' @param p_a1_young proportion of young people among the exposed (A = 1)\n#' @param d the (biased) standardized mean difference between exposed \n#' and un-exposed\nsimulate_confounding &lt;- function(n, m_young, p_a1_young, d) {\n    # this is to make sure overall group diff is equal to d\n    m_old &lt;- d / (2 * p_a1_young - 1)\n    M &lt;- c(m_young, m_old)\n    p &lt;- c(1 - p_a1_young, p_a1_young)\n    var_M &lt;- sum((M - sum(M * p))^2 * p)\n    SD &lt;- sqrt(1 - var_M)\n\n    params &lt;- data.frame(\n        n = c(\n            n * (1 - p_a1_young),\n            n * p_a1_young,\n            n * p_a1_young,\n            n * (1 - p_a1_young)\n        ),\n        A = c(0, 0, 1, 1),\n        U = c(2, 1, 2, 1),\n        mean = c(\n            m_young,\n            m_old,\n            m_young,\n            m_old\n        ),\n        SD = SD\n    )\n\n    pmap(\n        params,\n        function(n, A, U, mean, SD) {\n            data.frame(\n                A = A,\n                U = U,\n                y = rnorm(n, mean, SD)\n            )\n        }\n    ) %&gt;%\n    bind_rows() %&gt;%\n    mutate(\n        A = factor(A, labels = c(\"Control\", \"Gamers\")),\n        U = factor(U, labels = c(\"Old\", \"Young\"))\n    )\n}\n\nWhen then simulate a large data set with with a high proportion (85%) young people among the exposed.\n\n\nCode\nset.seed(1337)\nd &lt;- simulate_confounding(\n    n = 1e5,\n    m_young = 0,\n    p_a1_young = 0.85,\n    d = 0.5\n)\n\n\nWe can see a summary of the simulated data in Table 1.\n\n\nCode\nd %&gt;%\n    group_by(A) %&gt;%\n    summarise(\n        \"Prop. young\" = mean(U == \"Young\"),\n        \"Prop. old\" = mean(U == \"Old\"),\n        \"Mean\" = mean(y),\n        \"SD\" = sd(y),\n    ) %&gt;%\n    kable(digits = 2)\n\n\n\nTable 1: Summary of the simulated data\n\n\n\n\n(a) Young/old is the binary confounder, A is the exposure\n\n\nA\nProp. young\nProp. old\nMean\nSD\n\n\n\n\nControl\n0.15\n0.85\n0.61\n1\n\n\nGamers\n0.85\n0.15\n0.10\n1\n\n\n\n\n\n\n\nThe proportion of gamers is,\n\nmean(d$A == \"Gamers\")\n\n[1] 0.5\n\n\nand the biased difference between the exposed and non-exposed are\n\nmean(d[d$A == \"Gamers\", \"y\"]) - mean(d[d$A == \"Control\", \"y\"])\n\n[1] -0.5034944\n\n\nFigure 1 shows that the causal effect within strata is zero, and that the observed difference is outcomes is caused by the confounder.\n\n\nCode\np &lt;- ggplot(\n    d,\n    aes(\n        x = A,\n        y = y,\n        color = U,\n        group = interaction(U, A)\n    )\n) +\n    geom_violinhalf(\n        aes(\n            fill = U,\n            color = U\n        ),\n        alpha = 0.40,\n        position = \"identity\",\n        scale = \"count\",\n        flip = c(1, 2),\n    ) +\n    stat_summary(\n        aes(fill = U),\n        color = \"white\",\n        shape = 21,\n        geom = \"point\",\n        fun = \"mean\",\n        size = 3,\n    ) +\n    stat_summary(\n        aes(fill = U),\n        color = \"white\",\n        shape = 21,\n        geom = \"point\",\n        fun = \"mean\",\n        size = 3,\n    ) +\n    stat_summary(\n        aes(color = U, group = U),\n        geom = \"line\",\n        fun = \"mean\",\n        linewidth = 0.5\n    ) +\n    stat_summary(\n        aes(group = NA),\n        geom = \"point\",\n        fun = \"mean\",\n        fill = \"black\",\n        color = \"white\",\n        shape = 21,\n        size = 3,\n    ) +\n    stat_summary(\n        aes(group = NA),\n        geom = \"line\",\n        fun = \"mean\",\n        col = \"black\",\n        linewidth = 1,\n    ) +\n    labs(y = \"Mental health\", x = \"Observed outcomes\") +\n    scale_color_manual(values = c(\"Young\" = col1, \"Old\" = col2)) +\n    scale_fill_manual(values = c(\"Young\" = col1, \"Old\" = col2)) +\n    guides(\n        colour = guide_legend(\"Confounder\"),\n        fill = guide_legend(\"Confounder\")\n    ) +\n    lims(y = c(-2.5, 2.5)) +\n    theme_minimal() +\n    theme(\n        panel.grid.minor.x = element_blank(),\n        text = element_text(family = \"ArialMT\")\n    )\np\nggsave(\"figures/figure-confounding.svg\", p, width = 5, height = 4)\n\n\n\n\n\nFigure 1: Illustration of a third variable violating the exchangeability assumption\n\n\n\n\nUnsuprisingly, we get the same biased effect if we run a regression without including the confounder U.\n\nbroom::tidy(lm(y ~ A, data = d)) %&gt;% \n    kable(digits = 2)\n\n\nLinear regression without adjusting for the confounder \n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.61\n0\n191.73\n0\n\n\nAGamers\n-0.50\n0\n-112.35\n0\n\n\n\n\n\nAdjusting for U removes the confounding\n\nbroom::tidy(lm(y ~ A + U, data = d)) %&gt;% \n    kable(digits = 2)\n\n\nLinear regression adjusting for the confounder \n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.71\n0.00\n223.38\n0.00\n\n\nAGamers\n-0.01\n0.01\n-0.88\n0.38\n\n\nUYoung\n-0.71\n0.01\n-117.24\n0.00"
  },
  {
    "objectID": "index.html#exposure-version-confounding-example",
    "href": "index.html#exposure-version-confounding-example",
    "title": "Harmful Compared to What? The Problem of Gaming and Ill-defined Causal Effects - Online Supplement",
    "section": "Exposure-version confounding example",
    "text": "Exposure-version confounding example\nNow we will focus on exposure-version confounding. First, we write a function to generate simulated data with 4 version, 2 version among the unexposed and 2 versions for the exposed, both exposure and the version is infleunced by binary confounder (W).\n\n#' Simulate exposure-version confounder\n#'\n#' Will generate a dataset with a binary exposure-version confounder with an\n#' observed difference of a specific magnitude, while the true average\n#' causal effect is zero.\n#'\n#' @param n number of participants per group\n#' @param pr_W the probability of a participant being a man\n#' @param pr_A_W the probability of being exposed among the men\n#' @param pr_K_W_a0 the probability of K = 2 among the un-exposed men\n#' @param pr_K_W_a1 the probability of K = 2 among the exposed men\n#' @param sd_a0 total SD for the unexposed \n#' @param sd_a1 total SD for the exposed\n#' @param d the (biased) standardized mean difference between exposed and un-exposed\nsimulate_data &lt;- function(\n    n,\n    pr_W,\n    pr_A_W,\n    pr_K_W_a0,\n    pr_K_W_a1,\n    sd_a0,\n    sd_a1,\n    d\n) {\n    # confounder\n    W &lt;- rbinom(n, 1, pr_W)\n    # treatment\n    A &lt;- rbinom(\n        n,\n        1,\n        ifelse(W == 1, pr_A_W, 1 - pr_A_W)\n    )\n    # versions when A = 0\n    K_a0 &lt;- rbinom(\n        n,\n        1,\n        ifelse(W == 1, pr_K_W_a0, 1 - pr_K_W_a0)\n    ) + 1\n    # versions when A = 1\n    K_a1 &lt;- rbinom(\n        n,\n        1,\n        ifelse(W == 1, pr_K_W_a1, 1 - pr_K_W_a1)\n    ) + 1\n\n    # Code below appears more complicated than it is,\n    # it's just a bunch of conditional probabilities to get the correct \n    # proportion and variances. We do this so the total variance will be sd_a0² and sd_a1²,\n    # and the observed difference will be equal to `d`.\n    # Pr(A)\n    pr_A &lt;- pr_A_W * pr_W + (1 - pr_A_W) * (1 - pr_W)\n    # Solve for params in control group\n    # Pr(W = 1 | A = 0)\n    pr_w_a0 &lt;- pr_W * (1 - pr_A_W) / (1 - pr_A)\n    # Pr(K == 2 | A = 0)\n    p_k2_a0 &lt;- pr_w_a0 * pr_K_W_a0 + (1 - pr_w_a0) * (1 - pr_K_W_a0)\n    # Pr(K == 1 | A = 0)\n    p_k1_a0 &lt;- 1 - p_k2_a0\n    # E(Y0 | K = 1)\n    M_Y0_k1 &lt;- -0.5\n    # E(Y0 | K = 2)\n    M_Y0_k2 &lt;- 0.5\n    pr &lt;- c(p_k1_a0, p_k2_a0)\n    # solve for variance\n    M &lt;- c(M_Y0_k1, M_Y0_k2)\n    y_a0 &lt;- sum(M * pr)\n    var_M &lt;- sum((M - y_a0)^2 * pr)\n    sd_error_A0 &lt;- sqrt(sd_a0 - var_M)\n\n    # Solve for params in treatment group\n    # Pr(W = 1 | A = 1)\n    pr_w_a1 &lt;- pr_W * pr_A_W / (pr_A)\n    # Pr(K == 2 | A = 1)\n    p_k2_a1 &lt;- pr_w_a1 * pr_K_W_a1 + (1 - pr_w_a1) * (1 - pr_K_W_a1)\n    p_k1_a1 &lt;- 1 - p_k2_a1\n    pr &lt;- c(p_k1_a1, p_k2_a1)\n    SD_pooled &lt;- sqrt((sd_a0^2 * (1 - pr_A) + sd_a1^2 * pr_A))\n    es &lt;- d * SD_pooled\n    delta &lt;- (-2 * p_k1_a1 * M_Y0_k2 + M_Y0_k2 - (y_a0 - es)) / \n        (2 * p_k1_a1 - 1)\n    M &lt;- c(M_Y0_k1 - delta, M_Y0_k2 + delta)\n    y_a1 &lt;- sum(M * pr)\n    var_M &lt;- sum((M - y_a1)^2 * pr)\n    sd_error_A1 &lt;- sqrt(sd_a1^2 - var_M)\n\n    # generate outcomes\n    Y1 &lt;- model.matrix(~ 0 + as.factor(K_a1)) %*% \n        c(M_Y0_k1 - delta, M_Y0_k2 + delta) + \n        rnorm(n, 0, sd_error_A1)\n    Y0 &lt;- model.matrix(~ 0 + as.factor(K_a0)) %*% \n        c(M_Y0_k1, M_Y0_k2) + \n        rnorm(n, 0, sd_error_A0)\n    # combine data\n    list(\n        data = data.frame(\n            y = ifelse(A == 0, Y0, Y1),\n            y1 = Y1,\n            y0 = Y0,\n            K_a0,\n            K_a1,\n            K = ifelse(A == 0, K_a0, K_a1),\n            A = A,\n            W = W\n        ),\n        params = list(\n            \"pr_A\" = pr_A,\n            \"sd_error_A0\" = sd_error_A0,\n            \"sd_error_A1\" = sd_error_A1,\n            \"y_a0\" = y_a0,\n            \"y_a1\" = y_a1,\n            \"p_k1_a0\" = p_k1_a0,\n            \"p_k2_a0\" = p_k2_a0,\n            \"pr_w_a0\" = pr_w_a0,\n            \"pr_w_a1\" = pr_w_a1,\n            \"p_k1_a1\" = p_k1_a1,\n            \"p_k2_a1\" = p_k2_a1,\n            \"delta\" = delta,\n            \"SD_pooled\" = SD_pooled,\n            \"es\" = es\n        )\n    )\n}\n\nLet’s simulate a large data set, where 50% are exposed, among the exposed 80% are men, and among the exposed men 90% get K = 2, and among the unexposed men 90% also get K = 2.\n\n\nCode\npr_W &lt;- 0.5 # Pr(W)\npr_A_W &lt;- 0.8 # Pr(A | W)\npr_K_W_a0 &lt;- 0.1 # Pr(K | W, A = 0)\npr_K_W_a1 &lt;- 0.1 # Pr(K | W, A = 1)\nsd_a0 &lt;- 1\nsd_a1 &lt;- 1.2\nres &lt;- simulate_data(\n    n = 1e5,\n    pr_W = pr_W,\n    pr_A_W = pr_A_W,\n    pr_K_W_a0 = pr_K_W_a0,\n    pr_K_W_a1 = pr_K_W_a1,\n    d = 0.5,\n    sd_a0 = 1,\n    sd_a1 = 1.2\n)\nd &lt;- res$data\n\n\nCheck if the simulated data match our inputs.\n\n\nCode\n# control\nd %&gt;%\n    filter(A == 0) %&gt;%\n    summarise(\n        mean(K == 1),\n        mean(K == 2),\n        mean(y),\n        sd(y),\n        mean(W == 0)\n    ) %&gt;%\n    pivot_longer(\n        everything(),\n        names_to = \"parameter\",\n        values_to = \"value\"\n    ) %&gt;%\n    mutate(\n        theta = with(\n            res$params,\n            c(\n                p_k1_a0,\n                p_k2_a0,\n                y_a0,\n                sd_a0,\n                1 - pr_w_a0\n            )\n        )\n    ) %&gt;%\n    kable(digits = 2)\n\n\n\n\nTable 2: Summary of the unexposed group\n\n\nparameter\nvalue\ntheta\n\n\n\n\nmean(K == 1)\n0.26\n0.26\n\n\nmean(K == 2)\n0.74\n0.74\n\n\nmean(y)\n0.24\n0.24\n\n\nsd(y)\n1.00\n1.00\n\n\nmean(W == 0)\n0.80\n0.80\n\n\n\n\n\n\n\n\nCode\nd %&gt;%\n    filter(A == 1) %&gt;%\n    summarise(\n        mean(K == 1),\n        mean(K == 2),\n        mean(y),\n        sd(y),\n        mean(W == 0)\n    ) %&gt;%\n    pivot_longer(\n        everything(),\n        names_to = \"parameter\",\n        values_to = \"value\"\n    ) %&gt;%\n    mutate(\n        theta = with(\n            res$params,\n            c(\n                p_k1_a1,\n                p_k2_a1,\n                y_a1,\n                sd_a1,\n                1 - pr_w_a1\n            )\n        )\n    ) %&gt;%\n    kable(digits = 2)\n\n\n\n\nTable 3: Summary of the exposed group\n\n\nparameter\nvalue\ntheta\n\n\n\n\nmean(K == 1)\n0.74\n0.74\n\n\nmean(K == 2)\n0.26\n0.26\n\n\nmean(y)\n-0.32\n-0.31\n\n\nsd(y)\n1.20\n1.20\n\n\nmean(W == 0)\n0.20\n0.20\n\n\n\n\n\n\nWe also check so that proportions match stratified by age and version.\n\n\nCode\nd %&gt;%\n    group_by(A) %&gt;%\n    summarise(\n        \"Young K1\" = sum(K == 1 & W == 1) / sum(W == 1),\n        \"Young K2\" = sum(K == 2 & W == 1) / sum(W == 1),\n        \"Old K1\" = sum(K == 1 & W == 0) / sum(W == 0),\n        \"Old K2\" = sum(K == 2 & W == 0) / sum(W == 0),\n        n()\n    ) %&gt;%\n    kable(digits = 2)\n\n\n\n\nTable 4: Summary stratified by age and version\n\n\nA\nYoung K1\nYoung K2\nOld K1\nOld K2\nn()\n\n\n\n\n0\n0.9\n0.1\n0.1\n0.9\n50044\n\n\n1\n0.9\n0.1\n0.1\n0.9\n49956\n\n\n\n\n\n\nWe also see that the overall values are correct, inluding the biased effect.\n\n\nCode\npr_A &lt;- mean(d$A)\npooled_SD &lt;- sqrt(\n    sd(d[d$A == 0, \"y\"])^2 * (1 - pr_A) + \n    sd(d[d$A == 1, \"y\"])^2 * pr_A\n)\nm_diff &lt;- mean(d[d$A == 1, \"y\"]) - mean(d[d$A == 0, \"y\"])\n\ndata.frame(\n    parameter = c(\n        \"Pr(A)\",\n        \"mean diff\",\n        \"pooled SD\",\n        \"Cohen's d\"\n    ),\n    value = c(\n        pr_A,\n        m_diff,\n        pooled_SD,\n        m_diff / pooled_SD\n    ),\n    theta = with(\n        res$params,\n        c(\n            pr_A,\n            y_a1 - y_a0,\n            SD_pooled,\n            (y_a1 - y_a0) / SD_pooled\n        )\n    )\n) %&gt;%\n    kable(digits = 2)\n\n\n\n\nTable 5: Summary overal\n\n\nparameter\nvalue\ntheta\n\n\n\n\nPr(A)\n0.50\n0.50\n\n\nmean diff\n-0.55\n-0.55\n\n\npooled SD\n1.11\n1.10\n\n\nCohen’s d\n-0.50\n-0.50\n\n\n\n\n\n\n\nNaive analysis\nWe get a biased estimate if we naively look at the group differences\n\n\n\n\n\nFigure 2: Overall distribution of outcomes ignoring exposure-versions\n\n\n\n\n\n\nCode\nbroom::tidy(lm(y ~ A, data = d)) %&gt;% \n    kable(digits = 2)\n\n\n\n\nTable 6: Linear regression ignoring the exposure-version confounder\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.24\n0.00\n47.66\n0\n\n\nA\n-0.55\n0.01\n-79.22\n0\n\n\n\n\n\n\nIf we look at some diagnostics plots things look pretty normal.\n\n\nCode\nd_samp &lt;- d %&gt;%\n    group_by(A) %&gt;%\n    sample_n(1000) %&gt;%\n    ungroup()\nfit &lt;- lm(y ~ factor(A), data = d_samp)\nperformance::check_model(fit, check = c(\"qq\", \"pp_check\"))\nd_samp &lt;- d_samp %&gt;%\n    mutate(\n        yhat = fitted(fit),\n        res_sqrt = sqrt(abs(rstandard(fit)))\n    )\n\nggplot(\n    d_samp,\n    aes(x = factor(A), res_sqrt)\n    ) +\n    geom_boxplot() +\n    theme_minimal()\n\n\n\n\n\nFigure 3: Diagnostic plots\n\n\n\n\n\n\n\nFigure 4: Diagnostic plots\n\n\n\n\nIn Figure 5 we plot the exposure-version, and we and see that the overall comparison is a weighted average of the different exposure versions in each population. The overall comparison is biased when there is exposure-version confounding, however, we could compare specific versions.\n\n\\mathbb{E}(Y \\mid \\text{Control}, K = 2) - \\mathbb{E}(Y \\mid \\text{Gamers}, K = 1)\n\n\n\n\n\n\nFigure 5: The distribution of the different exposure-versions. Circles represent averages, black circles are averaged over both versions\n\n\n\n\nIf look at the data within each strata of the counfounder, in Figure 6 we see that overall impact among the older group is positive, whereas it is negative among men. This is interely driven by yound and old people being exposed to different versions of the exposure.\n\n\n\n\n\nFigure 6: The distribution of exposure-versions within each level of the confounder. Circles represent averages, black circles are averaged over both versions.\n\n\n\n\n\n\nAverage treatment effect (ATE)\nThe average causal effect of gaming is,\n\\begin{align*}\n\\text{ATE} &=\n\\mathbb{E}(Y^{\\text{Gamers}}) - \\mathbb{E}(Y^{\\text{Control}}) \\\\ &=\n\\sum_k \\mathbb{E}(Y \\mid \\text{Gaming}, K = k)\\Pr(K = k \\mid \\text{Gaming}) \\\\\n& - \\sum_k \\mathbb{E}(Y \\mid \\text{Control}, K = k)\\Pr(K = k \\mid \\text{Control})\n\\end{align*}\nthat is, we are comparing the outcomes if everyone in the population was gamers vs if noone was playing games.\nWe can get the correct estimate by adjusting for age, for instance, by including age as a covariate or using inverse probability weighting (IPW).\n\n# IPW\nmod1 &lt;- glm(\n    A ~ W,\n    data = d,\n    family = binomial(link = \"logit\")\n)\nd2 &lt;- d %&gt;%\n    mutate(\n        p = predict(mod1, type = \"response\")\n    ) %&gt;%\n    mutate(ipw = (A / p) + ((1 - A) / (1 - p)))\n\nbroom::tidy(\n    lm(y ~ A, weights = ipw, data = d2)\n    ) %&gt;% \n    kable(digits = 2)\n\n\n\nTable 7: IPW regression adjusting for age.\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.00\n0.01\n-0.85\n0.40\n\n\nA\n0.01\n0.01\n0.80\n0.42\n\n\n\n\n\n\n\nbroom::tidy(\n        lm(y ~ A + W, data = d)\n    ) %&gt;% \n    kable(digits = 2)\n\n\n\nTable 8: Outcome regression adjusting for age.\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.42\n0.00\n84.91\n0.00\n\n\nA\n0.01\n0.01\n0.73\n0.46\n\n\nW\n-0.93\n0.01\n-112.52\n0.00\n\n\n\n\n\n\nIn Figure 7 we plot the counterfactuals, and we see that the ATE is 0. However, we’d get a much more nuanced answer if we had data on the exposure version.\n\n\n\n\n\nFigure 7: The counterfactual distributions of the different exposure-versions for the whole population under both levels of the exposure, the overall difference represents the average treatment effect.\n\n\n\n\n\n\nAverage treatment effect on the treated (ATT).\nIt’s possible that most people do not have the ATE in mind wh en thinking about the causal effect of video games. It might be more intuitive to think what would happend to the population of gamers if they did not play games. This estimand is called the average treatment effect on the treated (ATT). If the control group was well-defined (i.e. lacked multiple versions), then we could get the ATT simply by comparing the average mental health among gamers with the average mental health among the control group.\n\\begin{align*}\n\\text{ATT} &= \\mathbb{E}(Y^{\\text{Gaming}} - Y^{\\text{Control}} \\mid A = 1) \\\\\n&= \\mathbb{E}(Y^{\\text{Gaming}} \\mid A = 1) - \\mathbb{E}(Y^{\\text{Control}} \\mid A = 1),\n\\end{align*}\n\\mathbb{E}(Y^{\\text{Control}} \\mid A = 1) is not something we could observe.\nWe can calculate the ATT using g-computation, the estimated ATT is shown in Table 9.\n\nlm_fit &lt;- lm(y ~ A * W, data = d)\nd_tx &lt;- d %&gt;% filter(A == 1)\nd_pred &lt;- tibble(\n    d_tx,\n    y_a0 = predict(\n        lm_fit,\n        newdata = mutate(d_tx, A = 0)\n    ),\n    y_a1 = d_tx$y,\n    att = y_a1 - y_a0\n)\n\n\n\nCode\nd_pred %&gt;%\n    summarize(\n        ATT = mean(y_a1 - y_a0)\n    ) %&gt;%\n    mutate(\n        ATT_true = d %&gt;%\n            filter(A == 1) %&gt;%\n            summarize(ATT = mean(y1 - y0)) %&gt;%\n            pull(ATT)\n    ) %&gt;%\n    kable(digits = 3)\n\n\n\n\nTable 9: ATT estimate caclulate using g-computation\n\n\nATT\nATT_true\n\n\n\n\n-0.074\n-0.085\n\n\n\n\n\n\nWe can plot what’s going on here. In Figure 8, y1 is the observed data among the exposed. y0 would not be observed, but since this is simulated data, we can plot it anyway. The dashed y0 curves show the obseved data. We see that if we compare the gamers with the non-gamers we get a counterfactual comparison that is wrong, the versions if Y0 is weigted incorrectly. This is caused by the exposure-version confounding.\n\n\nCode\ntmp &lt;- d %&gt;%\n    filter(A == 1) %&gt;%\n    pivot_longer(\n        cols = c(y1, y0)\n    ) %&gt;%\n    mutate(\n        K = case_when(\n            name == \"y1\" ~ K_a1,\n            name == \"y0\" ~ K_a0\n        ),\n        y = ifelse(name == \"y0\", y, NA),\n        group = paste0(name, \"k\", K)\n    )\np &lt;- ggplot(\n    data = tmp,\n    aes(\n        x = factor(name),\n        value, color = interaction(K, A),\n        group = interaction(K, A)\n    )\n) +\n    geom_violinhalf(\n        data = filter(tmp, name == \"y0\"),\n        aes(\n            fill = factor(K_a0), \n            color = factor(K_a0), \n            group = interaction(\"y0\", K_a0)\n        ),\n        alpha = 0.4,\n        position = \"identity\",\n        scale = \"count\",\n        flip = TRUE,\n    ) +\n    geom_violinhalf(\n        data = filter(d, A == 0),\n        aes(\n            x = \"y0\", \n            y = y, color = factor(K), \n            group = interaction(\"y0\", K)\n        ),\n        fill = NA,\n        linetype = \"dashed\",\n        alpha = 0.50,\n        position = \"identity\",\n        scale = \"count\",\n        flip = TRUE,\n    ) +\n    geom_violinhalf(\n        data = filter(tmp, name == \"y1\"),\n        aes(\n            fill = factor(K_a1), \n            color = factor(K_a1), \n            group = interaction(\"y1\", K_a1)\n        ),\n        alpha = 0.4,\n        position = \"identity\",\n        scale = \"count\",\n    ) +\n    stat_summary(\n        aes(fill = factor(K)),\n        color = \"white\",\n        shape = 21,\n        geom = \"point\",\n        fun = \"mean\",\n        size = 3,\n    ) +\n    stat_summary(\n        data = filter(d, A == 0),\n        aes(\n            x = \"y0\",\n             y = y, \n             color = factor(K)\n        ),\n        geom = \"point\",\n        shape = 1,\n        fun.y = \"mean\",\n        size = 5,\n    ) +\n    stat_summary(\n        aes(\n            color = factor(K), \n            group = factor(K)\n        ),\n        geom = \"line\",\n        fun.y = \"mean\",\n        linewidth = 0.5\n    ) +\n    stat_summary(\n        aes(\n            group = NA,\n            fill = \"Overall\"\n        ),\n        geom = \"point\",\n        fun = \"mean\",\n        color = \"white\",\n        shape = 21,\n        size = 3,\n    ) +\n    stat_summary(\n        data = filter(d, A == 0),\n        aes(\n            x = \"y0\", y = y,\n            group = NA,\n            color = \"Overall\",\n            fill = \"Overall\"\n        ),\n        geom = \"point\",\n        shape = 1,\n        fun.y = \"mean\",\n        size = 5,\n    ) +\n    stat_summary(\n        aes(group = NA, color = \"Overall\"),\n        geom = \"line\",\n        fun = \"mean\",\n        linewidth = 1,\n    ) +\n    lims(y = c(-2.5, 2.5)) +\n    labs(\n        y = \"Mental health\", \n        x = \"Counterfactual\"\n    ) +\n    scale_color_manual(\n        values = c(\n            \"1\" = col1, \n            \"2\" = col2, \n            \"Overall\" = \"black\"\n        )\n    ) +\n    scale_fill_manual(\n        values = c(\n            \"1\" = col1, \n            \"2\" = col2, \n            \"Overall\" = \"black\"\n        )\n    ) +\n    guides(\n        colour = guide_legend(\"Version\"),\n        fill = guide_legend(\"Version\")\n    ) +\n    theme_minimal() +\n    theme(\n        panel.grid.minor.x = element_blank(),\n        text = element_text(family = \"ArialMT\")\n    )\nggsave(\n    \"figures/figure-version-confounding-4.svg\", \n    p, \n    width = 5, \n    height = 4\n)\np\n\n\n\n\n\nFigure 8: The counterfactual distributions of the exposure-versions among only the gamers. The overall difference represents the average treatment effect on the treated. The dotted lines represent the distributions among non-gamers, and are added as a reference only. Circles represent averages, black circles are averaged over both versions"
  }
]